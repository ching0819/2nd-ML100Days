{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
    "\n",
    "\n",
    "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
    "\n",
    "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation, Input, AveragePooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "# 使用 resnet_layer 來建立我們的 ResNet 模型\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    # 建立卷積層\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    # 對輸入進行卷機，根據 conv_first 來決定 conv. bn, activation 的順序\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "# Resnet v1 共有三個 stage，每經過一次 stage，影像就會變小一半，但 channels 數量增加一倍。ResNet-20 代表共有 20 層 layers，疊越深參數越多\n",
    "def resnet_v1(input_shape, depth=8, num_classes=10):\n",
    "\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # 模型的初始設置，要用多少 filters，共有幾個 residual block （組成 ResNet 的單元）\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "    \n",
    "    # 建立 Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # 先對影像做第一次卷機\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    \n",
    "    # 總共建立 3 個 stage\n",
    "    for stack in range(3):\n",
    "        # 每個 stage 建立數個 residual blocks (數量視你的層數而訂，越多層越多 block)\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y]) # 此處把 featuremaps 與 上一層的輸入加起來 (欲更了解結構需閱讀原論文)\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # 建立分類\n",
    "    # 使用 average pooling，且 size 跟 featuremaps 的 size 一樣 （相等於做 GlobalAveragePooling）\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    \n",
    "    # 接上 Dense layer 來做分類\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # 建立模型\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256  \n",
    "epochs = 50\n",
    "num_classes = 10\n",
    "subtract_pixel_mean = True\n",
    "num_classes = 10\n",
    "n = 1\n",
    "version = 1\n",
    "depth = n * 6 + 2\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "input_shape = x_train.shape[1:]\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean \n",
    "    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\adm\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:104: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "Learning rate:  0.001\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   2320        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 16)   0           activation[0][0]                 \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 32)   4640        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16, 16, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   9248        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   544         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 16, 32)   0           conv2d_5[0][0]                   \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 64)     18496       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 8, 64)     256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 8, 64)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 64)     36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 64)     2112        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 64)     256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 8, 64)     0           conv2d_8[0][0]                   \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 64)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 64)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           650         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 78,666\n",
      "Trainable params: 78,186\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n",
      "ResNet8v1\n"
     ]
    }
   ],
   "source": [
    "model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "# 編譯模型，使用 Adam 優化器並使用學習率動態調整的函數，０代表在第一個 epochs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 1/50\n",
      "195/195 [==============================] - 148s 760ms/step - loss: 1.8445 - acc: 0.3602 - val_loss: 2.8029 - val_acc: 0.1659\n",
      "Learning rate:  0.001\n",
      "Epoch 2/50\n",
      "195/195 [==============================] - 143s 733ms/step - loss: 1.4514 - acc: 0.4998 - val_loss: 1.7579 - val_acc: 0.3808\n",
      "Learning rate:  0.001\n",
      "Epoch 3/50\n",
      "195/195 [==============================] - 143s 735ms/step - loss: 1.3024 - acc: 0.5569 - val_loss: 1.3579 - val_acc: 0.5322\n",
      "Learning rate:  0.001\n",
      "Epoch 4/50\n",
      "195/195 [==============================] - 142s 730ms/step - loss: 1.1959 - acc: 0.5983 - val_loss: 1.5345 - val_acc: 0.5070\n",
      "Learning rate:  0.001\n",
      "Epoch 5/50\n",
      "195/195 [==============================] - 142s 731ms/step - loss: 1.1240 - acc: 0.6251 - val_loss: 1.2911 - val_acc: 0.5676\n",
      "Learning rate:  0.001\n",
      "Epoch 6/50\n",
      "195/195 [==============================] - 142s 729ms/step - loss: 1.0622 - acc: 0.6452 - val_loss: 1.4103 - val_acc: 0.5531\n",
      "Learning rate:  0.001\n",
      "Epoch 7/50\n",
      "195/195 [==============================] - 142s 727ms/step - loss: 1.0238 - acc: 0.6615 - val_loss: 1.3168 - val_acc: 0.5884\n",
      "Learning rate:  0.001\n",
      "Epoch 8/50\n",
      "195/195 [==============================] - 143s 731ms/step - loss: 0.9857 - acc: 0.6736 - val_loss: 1.0481 - val_acc: 0.6466\n",
      "Learning rate:  0.001\n",
      "Epoch 9/50\n",
      "195/195 [==============================] - 142s 729ms/step - loss: 0.9531 - acc: 0.6834 - val_loss: 1.1529 - val_acc: 0.6182\n",
      "Learning rate:  0.001\n",
      "Epoch 10/50\n",
      "195/195 [==============================] - 142s 729ms/step - loss: 0.9261 - acc: 0.6961 - val_loss: 1.1877 - val_acc: 0.6162\n",
      "Learning rate:  0.001\n",
      "Epoch 11/50\n",
      "195/195 [==============================] - 142s 731ms/step - loss: 0.9030 - acc: 0.7039 - val_loss: 1.2505 - val_acc: 0.6054\n",
      "Learning rate:  0.001\n",
      "Epoch 12/50\n",
      "195/195 [==============================] - 143s 732ms/step - loss: 0.8783 - acc: 0.7139 - val_loss: 0.9880 - val_acc: 0.6782\n",
      "Learning rate:  0.001\n",
      "Epoch 13/50\n",
      "195/195 [==============================] - 142s 731ms/step - loss: 0.8552 - acc: 0.7233 - val_loss: 0.9733 - val_acc: 0.6875\n",
      "Learning rate:  0.001\n",
      "Epoch 14/50\n",
      "195/195 [==============================] - 143s 732ms/step - loss: 0.8381 - acc: 0.7286 - val_loss: 1.0734 - val_acc: 0.6642\n",
      "Learning rate:  0.001\n",
      "Epoch 15/50\n",
      "195/195 [==============================] - 143s 734ms/step - loss: 0.8202 - acc: 0.7358 - val_loss: 0.8537 - val_acc: 0.7220\n",
      "Learning rate:  0.001\n",
      "Epoch 16/50\n",
      "195/195 [==============================] - 142s 730ms/step - loss: 0.7954 - acc: 0.7448 - val_loss: 1.0533 - val_acc: 0.6685\n",
      "Learning rate:  0.001\n",
      "Epoch 17/50\n",
      "195/195 [==============================] - 143s 731ms/step - loss: 0.7815 - acc: 0.7489 - val_loss: 1.0640 - val_acc: 0.6663\n",
      "Learning rate:  0.001\n",
      "Epoch 18/50\n",
      "195/195 [==============================] - 142s 730ms/step - loss: 0.7638 - acc: 0.7569 - val_loss: 1.2252 - val_acc: 0.6354\n",
      "Learning rate:  0.001\n",
      "Epoch 19/50\n",
      "195/195 [==============================] - 143s 732ms/step - loss: 0.7554 - acc: 0.7594 - val_loss: 1.0540 - val_acc: 0.6647\n",
      "Learning rate:  0.001\n",
      "Epoch 20/50\n",
      "195/195 [==============================] - 143s 734ms/step - loss: 0.7418 - acc: 0.7630 - val_loss: 0.9379 - val_acc: 0.6977\n",
      "Learning rate:  0.001\n",
      "Epoch 21/50\n",
      "195/195 [==============================] - 143s 731ms/step - loss: 0.7271 - acc: 0.7694 - val_loss: 0.8326 - val_acc: 0.7414\n",
      "Learning rate:  0.001\n",
      "Epoch 22/50\n",
      "195/195 [==============================] - 142s 731ms/step - loss: 0.7193 - acc: 0.7718 - val_loss: 0.9073 - val_acc: 0.7166\n",
      "Learning rate:  0.001\n",
      "Epoch 23/50\n",
      "195/195 [==============================] - 142s 728ms/step - loss: 0.7055 - acc: 0.7760 - val_loss: 0.9717 - val_acc: 0.6918\n",
      "Learning rate:  0.001\n",
      "Epoch 24/50\n",
      "195/195 [==============================] - 144s 738ms/step - loss: 0.6968 - acc: 0.7810 - val_loss: 0.8449 - val_acc: 0.7336\n",
      "Learning rate:  0.001\n",
      "Epoch 25/50\n",
      "195/195 [==============================] - 143s 732ms/step - loss: 0.6869 - acc: 0.7834 - val_loss: 0.9440 - val_acc: 0.7064\n",
      "Learning rate:  0.001\n",
      "Epoch 26/50\n",
      "195/195 [==============================] - 144s 739ms/step - loss: 0.6782 - acc: 0.7872 - val_loss: 0.7661 - val_acc: 0.7554\n",
      "Learning rate:  0.001\n",
      "Epoch 27/50\n",
      "195/195 [==============================] - 143s 734ms/step - loss: 0.6731 - acc: 0.7885 - val_loss: 0.8193 - val_acc: 0.7466\n",
      "Learning rate:  0.001\n",
      "Epoch 28/50\n",
      "195/195 [==============================] - 142s 729ms/step - loss: 0.6633 - acc: 0.7916 - val_loss: 0.7834 - val_acc: 0.7528\n",
      "Learning rate:  0.001\n",
      "Epoch 29/50\n",
      "195/195 [==============================] - 143s 731ms/step - loss: 0.6468 - acc: 0.7984 - val_loss: 0.8251 - val_acc: 0.7489\n",
      "Learning rate:  0.001\n",
      "Epoch 30/50\n",
      "195/195 [==============================] - 143s 731ms/step - loss: 0.6441 - acc: 0.8002 - val_loss: 0.7336 - val_acc: 0.7689\n",
      "Learning rate:  0.001\n",
      "Epoch 31/50\n",
      "195/195 [==============================] - 142s 730ms/step - loss: 0.6330 - acc: 0.8019 - val_loss: 0.8197 - val_acc: 0.7500\n",
      "Learning rate:  0.001\n",
      "Epoch 32/50\n",
      "195/195 [==============================] - 142s 730ms/step - loss: 0.6344 - acc: 0.8008 - val_loss: 0.7728 - val_acc: 0.7633\n",
      "Learning rate:  0.001\n",
      "Epoch 33/50\n",
      "195/195 [==============================] - 142s 730ms/step - loss: 0.6229 - acc: 0.8053 - val_loss: 0.9545 - val_acc: 0.6992\n",
      "Learning rate:  0.001\n",
      "Epoch 34/50\n",
      "195/195 [==============================] - 143s 731ms/step - loss: 0.6177 - acc: 0.8071 - val_loss: 0.7346 - val_acc: 0.7713\n",
      "Learning rate:  0.001\n",
      "Epoch 35/50\n",
      "195/195 [==============================] - 143s 731ms/step - loss: 0.6071 - acc: 0.8116 - val_loss: 0.9924 - val_acc: 0.6987\n",
      "Learning rate:  0.001\n",
      "Epoch 36/50\n",
      "195/195 [==============================] - 143s 731ms/step - loss: 0.6051 - acc: 0.8120 - val_loss: 0.7236 - val_acc: 0.7788\n",
      "Learning rate:  0.001\n",
      "Epoch 37/50\n",
      "195/195 [==============================] - 143s 732ms/step - loss: 0.6024 - acc: 0.8134 - val_loss: 0.8575 - val_acc: 0.7425\n",
      "Learning rate:  0.001\n",
      "Epoch 38/50\n",
      "195/195 [==============================] - 142s 729ms/step - loss: 0.5949 - acc: 0.8182 - val_loss: 0.7523 - val_acc: 0.7670\n",
      "Learning rate:  0.001\n",
      "Epoch 39/50\n",
      "195/195 [==============================] - 142s 729ms/step - loss: 0.5904 - acc: 0.8196 - val_loss: 0.8130 - val_acc: 0.7571\n",
      "Learning rate:  0.001\n",
      "Epoch 40/50\n",
      "195/195 [==============================] - 143s 732ms/step - loss: 0.5830 - acc: 0.8198 - val_loss: 0.7759 - val_acc: 0.7693\n",
      "Learning rate:  0.001\n",
      "Epoch 41/50\n",
      "195/195 [==============================] - 142s 731ms/step - loss: 0.5786 - acc: 0.8209 - val_loss: 0.6794 - val_acc: 0.7893\n",
      "Learning rate:  0.001\n",
      "Epoch 42/50\n",
      "195/195 [==============================] - 142s 730ms/step - loss: 0.5799 - acc: 0.8216 - val_loss: 0.6905 - val_acc: 0.7881\n",
      "Learning rate:  0.001\n",
      "Epoch 43/50\n",
      "195/195 [==============================] - 142s 729ms/step - loss: 0.5699 - acc: 0.8237 - val_loss: 0.8472 - val_acc: 0.7433\n",
      "Learning rate:  0.001\n",
      "Epoch 44/50\n",
      "195/195 [==============================] - 142s 730ms/step - loss: 0.5621 - acc: 0.8290 - val_loss: 0.7519 - val_acc: 0.7661\n",
      "Learning rate:  0.001\n",
      "Epoch 45/50\n",
      "195/195 [==============================] - 142s 729ms/step - loss: 0.5623 - acc: 0.8284 - val_loss: 0.8223 - val_acc: 0.7577\n",
      "Learning rate:  0.001\n",
      "Epoch 46/50\n",
      "195/195 [==============================] - 142s 730ms/step - loss: 0.5560 - acc: 0.8295 - val_loss: 0.7005 - val_acc: 0.7887\n",
      "Learning rate:  0.001\n",
      "Epoch 47/50\n",
      "195/195 [==============================] - 142s 730ms/step - loss: 0.5516 - acc: 0.8300 - val_loss: 0.6282 - val_acc: 0.8096\n",
      "Learning rate:  0.001\n",
      "Epoch 48/50\n",
      "195/195 [==============================] - 142s 729ms/step - loss: 0.5465 - acc: 0.8325 - val_loss: 0.8488 - val_acc: 0.7358\n",
      "Learning rate:  0.001\n",
      "Epoch 49/50\n",
      "195/195 [==============================] - 142s 727ms/step - loss: 0.5423 - acc: 0.8335 - val_loss: 0.8618 - val_acc: 0.7456\n",
      "Learning rate:  0.001\n",
      "Epoch 50/50\n",
      "195/195 [==============================] - 142s 729ms/step - loss: 0.5469 - acc: 0.8336 - val_loss: 0.7290 - val_acc: 0.7844\n",
      "10000/10000 [==============================] - 8s 792us/step\n",
      "Test loss: 0.728971413851\n",
      "Test accuracy: 0.7844\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# 使用動態調整學習率\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# 使用自動降低學習率 (當 validation loss 連續 5 次沒有下降時，自動降低學習率)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "# 設定 callbacks\n",
    "callbacks = [lr_reducer, lr_scheduler]\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0)\n",
    "\n",
    "# 將資料送進 ImageDataGenrator 中做增強\n",
    "datagen.fit(x_train)\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=int(len(x_train)//batch_size),\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=epochs, verbose=1, workers=4,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "# 評估我們的模型\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
