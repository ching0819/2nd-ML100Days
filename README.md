# [ML100Days](https://ai100-2.cupoy.com/) 
![alt](./photo/banner.PNG)
![alt](./photo/01.PNG)  

#### Part 1 Clean Data and Data Preprocessing (資料清理數據前處理)
- Day 01 : Data Introduction and Assessment / 資料介紹與評估資料
- Day 02 : Exploratory Data Analysis(EDA) / 讀取資料EDA: Data summary
- Day 03 : Build Pandas DataFrame / 新建dataframe
- Day 04 : Pandas Data Types / 欄位的資料類型介紹及處理
- Day 05 : EDA Distribution / 資料分佈
- Day 06 : Handle Outlier Data / Outlier及處理
- Day 07 : Normalize Continuous Data /常用的數值取代：中位數與分位數連續數值標準化
- Day 08 : DataFrame operation / Data frame merge /常用的 DataFrame 操作
- Day 09 : EDA Correlation 1 / 程式實作 EDA: correlation/相關係數簡介
- Day 10 : EDA Correlation 2 / EDA from Correlation
- Day 11 : Kernal Density Estimation (KDE) / 不同數值範圍間的特徵如何檢視/繪圖與樣式Kernel Density Estimation (KDE)
- Day 12 : Discretization Method / 把連續型變數離散化
- Day 13 : Implement Discretization Method / 程式實作:把連續型變數離散化
- Day 14 : Subplot using Matplotib / 繪製子圖
- Day 15 : Heatmap and Grid-plot / 繪製Heatmap & Grid-plot
- Day 16 : Logistic Regression 模型初體驗 Logistic Regression
#### Part 2 Feature Engineering (資料科學特徵工程技術)
- Day 17 : Introduction of Feature Engineering
- Day 18 : Feture Types
- Day 19 : [Value Type] Insert Value for Lost Information
- Day 20 : [Value Type] Remove Outlier
- Day 21 : [Value Type] Remove Bias
- Day 22 : [Class Type] One-Hot and Label Encoding
- Day 23 : [Class Type] Mean Encoding
- Day 24 : [Class Type] Other Advanced Processing
- Day 25 : [Time Type] Time Cycle
- Day 26 : Feature Combination (Value and Value)
- Day 27 : Feature Combination (Value and Class)
- Day 28 : Feature Selection
- Day 29 : Feature Estimation
- Day 30 : Leaf Encoding on Class Type Feature
#### Part 3 Machine Learning Model Building (機器學習基礎模型建立)
- Day 31 : Introduction of Machine Learning
- Day 32 : Framework and Process in Machine Learning
- Day 33 : How to Teach Machine?
- Day 34 : Split Training and Evaluation Set
- Day 35 : Regression vs. Classification
- Day 36 : Evaluation Metrics
- Day 37 : Regression Model Introdoction (Linear / Logistic)
- Day 38 : Rgression Model Implement (Linear / Logistic)
- Day 39 : Regression Model Introdoction (LASSO / Ridge)
- Day 40 : Rgression Model Implement (LASSO / Ridge)
- Day 41 : Tree Based Model Introdoction (Decision Tree)
- Day 42 : Tree Based Model Implement (Decision Tree)
- Day 43 : Tree Based Model Introdoction (Random Forest)
- Day 44 : Tree Based Model Implement (Random Forest)
- Day 45 : Tree Based Model Introdoction (Gradient Boosting Machine)
- Day 46 : Tree Based Model Implement (Gradient Boosting Machine)
#### Part 4 Machine Learning Fine-tuning (機器學習調整參數)
- Day 47 : Hyper-Parameters Tuning and Optimization
- Day 48 : Introduction of Kaggle
- Day 49 : Bleding Method
- Day 50 : Stacking Method
#### Mid-Term Exam
- Day 51 : Mid-Term Exam (1/3)
- Day 52 : Mid-Term Exam (2/3)
- Day 53 : Mid-Term Exam (3/3)
#### Part 5 Unsupervised Learning (非監督式機器學習)
- Day 54 : Introduction of Unsupervised Learning
- Day 55 : Clustering Method
- Day 56 : K-Mean
- Day 57 : Hierarchical Clustering
- Day 58 : Hierarchical Clustering on 2D Toy Dataset
- Day 59 : Dimension Reduction - PCA
- Day 60 : PCA on MNIST
- Day 61 : Dimension Reduction - T-SNE
- Day 62 : T-SNE Implement
#### Part 6 Deep Learning Theory and Implement (深度學習理論與實作)
- Day 63 : Introduction of Neural Netork
- Day 64 : Experience on TensorFlow PlayGround (Learning Rate)
- Day 65 : Experience on TensorFlow PlayGround (Activation Function/ Regularization)
#### Part 7 Deep Learning on Keras (初探深度學習使用 Keras)
- Day 66 : Introducion of Keras
- Day 67 : Keras Dataset
- Day 68 : Keras Sequential API
- Day 69 : Keras Module API
- Day 70 : Multi-Layer Perception (MLP)
- Day 71 : Loss Functions
- Day 72 : Activation Function
- Day 73 : Gradient Descend (1/2)
- Day 74 : Gradient Descend (2/2)
- Day 75 : Back Propagation
- Day 76 : Optimizers
- Day 77 : Validation and Overfitting
- Day 78 : KeyNote before Training Model
- Day 79 : Learning Rate Effect
- Day 80 : Combination of Optomizer and Learning Rate
- Day 81 : Avoid Overfitting - Regularization
- Day 82 : Avoid Overfitting - Dropout
- Day 83 : Avoid Overfitting - Batch Normalization
- Day 84 : Avoid Overfitting - Hyper-Parameters Tuning and Comparison
- Day 85 : Avoid Overfitting - Early Stop
- Day 86 : Saving and Restoring Model
- Day 87 : Learning Rate Decay
- Day 88 : Design your Keras Callbacks Function
- Day 89 : Design your Loss Funciton
- Day 90 : Image Recognition using Tranditional Computer Vsion Methods
- Day 91 : Image Recognition using Machine Learning Model
#### Part 8 Convolutional Neural Network (CNN) in Deep Learning (深度學習應用卷積神經網路)
- Day 92 : Introdoction of CNN (1/2)
- Day 93 : Introdoction of CNN (2/2)
- Day 94 : Parameters Tuning in CNN Layer
- Day 95 : Pooling Layer in Keras
- Day 96 : CNN Layer in Keras
- Day 97 : CNN vs. DNN on CIFAR-10
- Day 98 : Data Generator in Keras
- Day 99 : Data Augmentation in Keras
- Day 100 : Transfer Learning
#### Final Exam
- Day 101 : Final Exam (1/3)
- Day 102 : Final Exam (2/3)
- Day 103 : Final Exam (3/3)
#### Part 9 Bonus (進階補充)


