# [ML100Days](https://ai100-2.cupoy.com/) 
![alt](./photo/banner.PNG)
![alt](./photo/01.PNG)  

#### Part 1 Clean Data and Data Preprocessing (資料清理數據前處理)
- Day 01 : Data Introduction and Assessment
- Day 02 : Exploratory Data Analysis(EDA)
- Day 03 : Build Pandas DataFrame
- Day 04 : Pandas Data Types
- Day 05 : EDA Distribution
- Day 06 : Handle Outlier Data
- Day 07 : Normalize Continuous Data
- Day 08 : DataFrame operation / Data frame merge
- Day 09 : EDA Correlation 1
- Day 10 : EDA Correlation 2
- Day 11 : Kernal Density Estimation (KDE)
- Day 12 : Discretization Method
- Day 13 : Implement Discretization Method
- Day 14 : Subplot using Matplotib
- Day 15 : Heatmap and Grid-plot
- Day 16 : Logistic Regression
#### Part 2 Feature Engineering (資料科學特徵工程技術)
Day 17 : Introduction of Feature Engineering
Day 18 : Feture Types
Day 19 : [Value Type] Insert Value for Lost Information
Day 20 : [Value Type] Remove Outlier
Day 21 : [Value Type] Remove Bias
Day 22 : [Class Type] One-Hot and Label Encoding
Day 23 : [Class Type] Mean Encoding
Day 24 : [Class Type] Other Advanced Processing
Day 25 : [Time Type] Time Cycle
Day 26 : Feature Combination (Value and Value)
Day 27 : Feature Combination (Value and Class)
Day 28 : Feature Selection
Day 29 : Feature Estimation
Day 30 : Leaf Encoding on Class Type Feature
#### Part 3 Machine Learning Model Building (機器學習基礎模型建立)
Day 31 : Introduction of Machine Learning
Day 32 : Framework and Process in Machine Learning
Day 33 : How to Teach Machine?
Day 34 : Split Training and Evaluation Set
Day 35 : Regression vs. Classification
Day 36 : Evaluation Metrics
Day 37 : Regression Model Introdoction (Linear / Logistic)
Day 38 : Rgression Model Implement (Linear / Logistic)
Day 39 : Regression Model Introdoction (LASSO / Ridge)
Day 40 : Rgression Model Implement (LASSO / Ridge)
Day 41 : Tree Based Model Introdoction (Decision Tree)
Day 42 : Tree Based Model Implement (Decision Tree)
Day 43 : Tree Based Model Introdoction (Random Forest)
Day 44 : Tree Based Model Implement (Random Forest)
Day 45 : Tree Based Model Introdoction (Gradient Boosting Machine)
Day 46 : Tree Based Model Implement (Gradient Boosting Machine)
#### Part 4 Machine Learning Fine-tuning (機器學習調整參數)
Day 47 : Hyper-Parameters Tuning and Optimization
Day 48 : Introduction of Kaggle
Day 49 : Bleding Method
Day 50 : Stacking Method
#### Mid-Term Exam
Day 51 : Mid-Term Exam (1/3)
Day 52 : Mid-Term Exam (2/3)
Day 53 : Mid-Term Exam (3/3)
#### Part 5 Unsupervised Learning (非監督式機器學習)
Day 54 : Introduction of Unsupervised Learning
Day 55 : Clustering Method
Day 56 : K-Mean
Day 57 : Hierarchical Clustering
Day 58 : Hierarchical Clustering on 2D Toy Dataset
Day 59 : Dimension Reduction - PCA
Day 60 : PCA on MNIST
Day 61 : Dimension Reduction - T-SNE
Day 62 : T-SNE Implement
#### Part 6 Deep Learning Theory and Implement (深度學習理論與實作)
Day 63 : Introduction of Neural Netork
Day 64 : Experience on TensorFlow PlayGround (Learning Rate)
Day 65 : Experience on TensorFlow PlayGround (Activation Function/ Regularization)
#### Part 7 Deep Learning on Keras (初探深度學習使用 Keras)
Day 66 : Introducion of Keras
Day 67 : Keras Dataset
Day 68 : Keras Sequential API
Day 69 : Keras Module API
Day 70 : Multi-Layer Perception (MLP)
Day 71 : Loss Functions
Day 72 : Activation Function
Day 73 : Gradient Descend (1/2)
Day 74 : Gradient Descend (2/2)
Day 75 : Back Propagation
Day 76 : Optimizers
Day 77 : Validation and Overfitting
Day 78 : KeyNote before Training Model
Day 79 : Learning Rate Effect
Day 80 : Combination of Optomizer and Learning Rate
Day 81 : Avoid Overfitting - Regularization
Day 82 : Avoid Overfitting - Dropout
Day 83 : Avoid Overfitting - Batch Normalization
Day 84 : Avoid Overfitting - Hyper-Parameters Tuning and Comparison
Day 85 : Avoid Overfitting - Early Stop
Day 86 : Saving and Restoring Model
Day 87 : Learning Rate Decay
Day 88 : Design your Keras Callbacks Function
Day 89 : Design your Loss Funciton
Day 90 : Image Recognition using Tranditional Computer Vsion Methods
Day 91 : Image Recognition using Machine Learning Model
#### Part 8 Convolutional Neural Network (CNN) in Deep Learning (深度學習應用卷積神經網路)
Day 92 : Introdoction of CNN (1/2)
Day 93 : Introdoction of CNN (2/2)
Day 94 : Parameters Tuning in CNN Layer
Day 95 : Pooling Layer in Keras
Day 96 : CNN Layer in Keras
Day 97 : CNN vs. DNN on CIFAR-10
Day 98 : Data Generator in Keras
Day 99 : Data Augmentation in Keras
Day 100 : Transfer Learning
#### Final Exam
Day 101 : Final Exam (1/3)
Day 102 : Final Exam (2/3)
Day 103 : Final Exam (3/3)
#### Part 9 Bonus (進階補充)


